<!DOCTYPE html>
<html lang="es">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>‚ö° Cuantizaci√≥n IA - Benchmark Phi-3</title>

<link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700;800&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

<style>

:root{
  --primary:linear-gradient(135deg,#667eea,#764ba2);
  --success:linear-gradient(135deg,#10b981,#059669);
  --bg:#f1f5f9;
  --card:#ffffff;
  --shadow:0 20px 45px rgba(0,0,0,.12);
}

*{margin:0;padding:0;box-sizing:border-box;}

body{
  font-family:'Inter',sans-serif;
  background:var(--bg);
  color:#1e293b;
  line-height:1.7;
}

/* HERO */
.hero{
  background:var(--primary);
  color:white;
  text-align:center;
  padding:90px 20px;
}

.hero h1{
  font-size:clamp(2.4rem,6vw,4rem);
  font-weight:800;
}

.hero p{
  margin-top:15px;
  font-size:1.2rem;
  opacity:.9;
}

.pill{
  display:inline-block;
  margin:8px;
  padding:6px 14px;
  border-radius:999px;
  background:rgba(255,255,255,.2);
  font-weight:600;
  font-size:.85rem;
}

/* CONTAINER */
.container{
  max-width:1100px;
  margin:auto;
  padding:40px 20px;
}

/* CARDS */
.section{
  background:var(--card);
  padding:40px;
  border-radius:22px;
  margin-bottom:40px;
  box-shadow:var(--shadow);
}

.section h3{
  font-size:1.6rem;
  margin-bottom:20px;
  display:flex;
  align-items:center;
  gap:12px;
  background:var(--primary);
  -webkit-background-clip:text;
  -webkit-text-fill-color:transparent;
}

.section p{
  font-size:1.08rem;
  color:#475569;
  margin-bottom:18px;
}

/* IM√ÅGENES N√çTIDAS */
.section img{
  width:100%;
  max-width:900px;
  display:block;
  margin:0 auto 25px;
  border-radius:14px;
  box-shadow:0 15px 35px rgba(0,0,0,.18);

  image-rendering:optimizeQuality;
  image-rendering:-webkit-optimize-contrast;
}

/* GRID COMPARACI√ìN */
.grid{
  display:grid;
  grid-template-columns:repeat(auto-fit,minmax(260px,1fr));
  gap:25px;
  margin-top:20px;
}

.card{
  text-align:center;
  padding:25px;
  border-radius:18px;
  background:linear-gradient(135deg,rgba(102,126,234,.12),rgba(118,75,162,.12));
  border:2px solid rgba(102,126,234,.25);
}

.card h4{
  font-size:1.3rem;
  margin-bottom:10px;
}

.metric{
  font-size:2rem;
  font-weight:800;
  background:var(--success);
  -webkit-background-clip:text;
  -webkit-text-fill-color:transparent;
}

/* CONCLUSI√ìN */
.conclusion{
  background:var(--success);
  color:white;
  text-align:center;
  padding:70px 30px;
}

.conclusion h2{
  font-size:2.2rem;
  margin-bottom:20px;
}

@media(max-width:768px){
  .section{padding:25px;}
}

</style>
</head>

<body>

<!-- HERO -->
<section class="hero">
  <h1><i class="fas fa-compress-arrows-alt"></i> Cuantizaci√≥n de Modelos IA</h1>
  <p>Benchmark real Phi-3 Mini ¬∑ LM Studio ¬∑ RTX 5060 Ti</p>

  <div>
    <span class="pill">FP16</span>
    <span class="pill">Q8 GGUF</span>
    <span class="pill">Local Inference</span>
    <span class="pill">Performance Test</span>
  </div>
</section>


<div class="container">

<!-- INTRO -->
<div class="section">
  <h3><i class="fas fa-brain"></i> ¬øQu√© es la cuantizaci√≥n?</h3>
  <p>
    La cuantizaci√≥n reduce la precisi√≥n num√©rica de los pesos del modelo
    para disminuir consumo de memoria y acelerar la inferencia.
    En este experimento se compara el modelo Phi-3 Mini en formato
    FP16 original frente a su versi√≥n Q8 cuantizada.
  </p>
</div>

<!-- Q8 -->
<div class="section">
  <img src="cu1.png">
  <h3><i class="fas fa-bolt"></i> Rendimiento Q8</h3>

  <p>
    El modelo cuantizado alcanza <strong>64.59 tokens/segundo</strong>
    con una latencia inicial de solo <strong>0.02 segundos</strong>.
  </p>

  <div class="grid">
    <div class="card">
      <h4>Velocidad</h4>
      <div class="metric">64.59 t/s</div>
    </div>

    <div class="card">
      <h4>Primer Token</h4>
      <div class="metric">0.02 s</div>
    </div>
  </div>
</div>

<!-- TAMA√ëO -->
<div class="section">
  <img src="cu2.png">
  <h3><i class="fas fa-file"></i> Tama√±o Q8</h3>
  <p>
    El modelo ocupa solo <strong>3.78 GB</strong>,
    reduciendo casi un 50% el tama√±o respecto al FP16.
  </p>
</div>

<!-- FP16 -->
<div class="section">
  <img src="cu3.png">
  <h3><i class="fas fa-microchip"></i> Rendimiento FP16</h3>
  <p>
    La versi√≥n original FP16 alcanza 52.11 tokens/s,
    ofreciendo m√°xima precisi√≥n pero mayor consumo de VRAM.
  </p>
</div>

<!-- COMPARACI√ìN -->
<div class="section">
  <img src="cu4.png">
  <h3><i class="fas fa-scale-balanced"></i> Comparativa Final</h3>

  <div class="grid">
    <div class="card">
      <h4>üü¢ Q8 Cuantizado</h4>
      <div class="metric">3.78 GB</div>
      <p>64.59 tokens/s</p>
    </div>

    <div class="card">
      <h4>üî¥ FP16 Original</h4>
      <div class="metric">7.11 GB</div>
      <p>52.11 tokens/s</p>
    </div>
  </div>
</div>

</div>

<!-- CONCLUSI√ìN -->
<section class="conclusion">
  <h2><i class="fas fa-chart-line"></i> Resultado del Benchmark</h2>

  <p style="font-size:1.3rem;max-width:800px;margin:auto;">
    ‚úÖ 47% menos tama√±o<br>
    ‚úÖ ~24% m√°s velocidad<br>
    ‚úÖ Inferencia local optimizada en GPU dom√©stica
  </p>
</section>

</body>
</html>
