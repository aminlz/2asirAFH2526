<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <title>Pre entrenamiento – Proyecto NanoQuijote</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root {
      --bg: #f3f4f6;          /* gris claro de fondo */
      --bg-card: #ffffff;     /* tarjetas blancas */
      --accent: #f97316;      /* naranja principal */
      --accent-soft: #fed7aa; /* naranja suave */
      --text: #111827;        /* gris muy oscuro */
      --text-muted: #6b7280;  /* gris medio */
      --border: #d1d5db;      /* borde gris claro */
      --border-hover: #9ca3af;/* borde hover imagen */
    }
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      background: radial-gradient(circle at top, #e5e7eb 0, #f3f4f6 55%);
      color: var(--text);
      line-height: 1.6;
    }
    a { color: var(--accent); text-decoration: none; }
    a:hover { text-decoration: underline; }

    header {
      position: sticky;
      top: 0;
      z-index: 50;
      background: linear-gradient(to right, #111827, #1f2937);
      color: #f9fafb;
      box-shadow: 0 6px 16px rgba(0,0,0,0.15);
    }
    .header-inner {
      max-width: 1100px;
      margin: 0 auto;
      padding: 1.1rem 1.5rem;
      display: flex;
      justify-content: space-between;
      align-items: center;
      gap: 1rem;
    }
    .logo {
      display: flex;
      align-items: center;
      gap: 0.75rem;
    }
    .logo-icon {
      width: 34px;
      height: 34px;
      border-radius: 12px;
      background: radial-gradient(circle at 30% 30%, #fed7aa, #f97316);
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: 700;
      font-size: 0.9rem;
      color: #111827;
    }
    .logo-text {
      display: flex;
      flex-direction: column;
      gap: 0.1rem;
    }
    .logo-text span:first-child {
      font-weight: 700;
      letter-spacing: 0.12em;
      text-transform: uppercase;
      font-size: 0.8rem;
    }
    .logo-text span:last-child {
      font-size: 0.75rem;
      color: #e5e7eb;
    }
    nav {
      display: flex;
      gap: 1.2rem;
      font-size: 0.85rem;
    }
    nav a {
      color: #e5e7eb;
      opacity: 0.8;
    }
    nav a:hover {
      opacity: 1;
      color: #f97316;
    }

    main {
      max-width: 1100px;
      margin: 2rem auto 3rem;
      padding: 0 1.5rem 3rem;
    }

    .hero {
      margin-bottom: 2.5rem;
      text-align: left;
    }
    .hero-title {
      font-size: clamp(2rem, 3.1vw, 2.7rem);
      font-weight: 800;
      letter-spacing: -0.03em;
      color: #111827;
      margin-bottom: 0.4rem;
    }
    .hero-sub {
      color: var(--text-muted);
      max-width: 40rem;
      margin-bottom: 1.2rem;
    }
    .hero-tags {
      display: flex;
      flex-wrap: wrap;
      gap: 0.5rem;
      font-size: 0.8rem;
    }
    .tag {
      border-radius: 999px;
      padding: 0.2rem 0.7rem;
      border: 1px solid rgba(249,115,22,0.35);
      background: rgba(255,255,255,0.9);
      color: #7c2d12;
    }

    .section-title {
      font-size: 1.1rem;
      font-weight: 700;
      margin-bottom: 1rem;
      display: flex;
      align-items: center;
      gap: 0.6rem;
      color: #111827;
    }
    .section-title::before {
      content: "";
      width: 5px;
      height: 20px;
      border-radius: 999px;
      background: linear-gradient(to bottom, #f97316, #fb923c);
    }

    .capture {
      margin-bottom: 2rem;
      background: var(--bg-card);
      border-radius: 1rem;
      padding: 1.1rem 1.1rem 1.2rem;
      border: 1px solid var(--border);
      box-shadow: 0 12px 30px rgba(15,23,42,0.09);
    }
    .capture-header {
      display: flex;
      justify-content: space-between;
      align-items: baseline;
      gap: 0.5rem;
      margin-bottom: 0.8rem;
      border-bottom: 1px dashed #e5e7eb;
      padding-bottom: 0.4rem;
    }
    .capture-title {
      font-size: 0.95rem;
      font-weight: 600;
      color: #111827;
    }
    .capture-tagline {
      font-size: 0.8rem;
      color: var(--text-muted);
    }

    .capture-image-wrapper {
      margin-bottom: 0.9rem;
    }
    .capture-image {
      border-radius: 0.85rem;
      border: 2px solid var(--border);
      overflow: hidden;
      transition: border-color 0.18s ease, box-shadow 0.18s ease, transform 0.15s ease;
      background: #111827;
    }
    .capture-image img {
      display: block;
      width: 100%;
      height: auto;
    }
    .capture-image:hover {
      border-color: var(--border-hover);     /* resalta gris más marcado */
      box-shadow: 0 14px 28px rgba(55,65,81,0.35);
      transform: translateY(-1px);
    }

    .capture-body {
      font-size: 0.92rem;
      color: var(--text);
    }
    .capture-body p {
      margin-bottom: 0.55rem;
    }

    .pill-row {
      display: flex;
      flex-wrap: wrap;
      gap: 0.35rem;
      margin-bottom: 0.7rem;
    }
    .pill {
      font-size: 0.75rem;
      padding: 0.15rem 0.55rem;
      border-radius: 999px;
      background: var(--accent-soft);
      color: #7c2d12;
      border: 1px solid rgba(248,113,22,0.3);
    }

    footer {
      border-top: 1px solid #e5e7eb;
      background: #e5e7eb;
      color: var(--text-muted);
      font-size: 0.8rem;
      padding: 1rem 1.5rem 1.4rem;
    }
    .footer-inner {
      max-width: 1100px;
      margin: 0 auto;
      display: flex;
      justify-content: space-between;
      flex-wrap: wrap;
      gap: 0.5rem;
    }

    @media (max-width: 768px) {
      .header-inner { flex-direction: column; align-items: flex-start; }
      nav { width: 100%; justify-content: flex-start; flex-wrap: wrap; }
      main { padding-inline: 1rem; }
      .capture { padding-inline: 0.9rem; }
    }
  </style>
</head>
<body>

<header>
  <div class="header-inner">
    <div class="logo">
      <div class="logo-icon">NQ</div>
      <div class="logo-text">
        <span>Pre entrenamiento</span>
        <span>Proyecto NanoQuijote · Documentación</span>
      </div>
    </div>
    <nav>
      <a href="#intro">Inicio</a>
      <a href="#capturas">Capturas</a>
    </nav>
  </div>
</header>

<main>
  <section class="hero" id="intro">
    <h1 class="hero-title">Pre entrenamiento del modelo de lenguaje</h1>
    <p class="hero-sub">
      Flujo de trabajo desde la descarga del corpus del Quijote hasta el guardado del modelo entrenado,
      documentado paso a paso con capturas claras y explicación debajo de cada imagen.
    </p>
    <div class="hero-tags">
      <span class="tag">PowerShell</span>
      <span class="tag">PyTorch · CUDA</span>
      <span class="tag">Modelo de caracteres</span>
      <span class="tag">Documentación técnica</span>
    </div>
  </section>

  <section id="capturas">
    <h2 class="section-title">Secuencia de capturas</h2>

    <!-- Captura 1 -->
    <article class="capture">
      <div class="capture-header">
        <div class="capture-title">Captura 1 · Descarga del corpus</div>
        <div class="capture-tagline">Obtención y comprobación de <code>quijote.txt</code>.</div>
      </div>
      <div class="capture-image-wrapper">
        <div class="capture-image">
          <img src="image3.png" alt="Descarga y verificación del archivo quijote.txt en PowerShell" />
        </div>
      </div>
      <div class="capture-body">
        <div class="pill-row">
          <span class="pill">Invoke-WebRequest</span>
          <span class="pill">Get-Content</span>
          <span class="pill">Corpus Quijote</span>
        </div>
        <h3>Captura 1 – Descarga y preparación del script</h3>
<p>
  En la primera captura se utiliza el comando <code>Invoke-WebRequest</code> para descargar el libro del Quijote desde
  Project Gutenberg y guardarlo en un archivo llamado <code>quijote.txt</code>.
</p>
<p>
  Después se ejecuta <code>Get-Content -TotalCount 5</code> para mostrar las primeras líneas del archivo y verificar
  que la descarga se ha realizado correctamente.
</p>
<p>
  A continuación se crea el archivo <code>entrenar.py</code> mediante <code>Set-Content</code>, introduciendo en él el
  código encargado de preparar los datos y definir el modelo de lenguaje.
</p>
<p>
  Finalmente, se ejecuta <code>python entrenar.py</code>, lo que pone en marcha el proceso de entrenamiento usando el
  texto del Quijote como corpus.
</p>

<hr />
      </div>
    </article>

    <!-- Captura 2 -->
    <article class="capture">
      <div class="capture-header">
        <div class="capture-title">Captura 2 · Creación del script</div>
        <div class="capture-tagline">Generación de <code>entrenar.py</code> con el código del modelo.</div>
      </div>
      <div class="capture-image-wrapper">
        <div class="capture-image">
          <img src="image1.png" alt="Creación del archivo entrenar.py en la consola" />
        </div>
      </div>
      <div class="capture-body">
        <div class="pill-row">
          <span class="pill">Set-Content</span>
          <span class="pill">entrenar.py</span>
          <span class="pill">Preparación del entorno</span>
        </div>
       <h3>Captura 2 – Información inicial del entrenamiento</h3>
<p>
  En la segunda captura se observa la salida inicial del script <code>entrenar.py</code>.
</p>
<p>
  Primero se indica que se está utilizando el dispositivo <code>cuda</code> y la GPU disponible
  (NVIDIA GeForce RTX 4070 Ti) junto con la memoria de vídeo libre.
</p>
<p>
  A continuación se calcula el vocabulario de caracteres únicos del texto y se muestra el número total de tokens,
  diferenciando entre tokens de entrenamiento y de validación.
</p>
<p>
  También se imprime el número total de parámetros del modelo y una estimación de la memoria que ocupa.
</p>
<p>
  Por último comienza el bucle de entrenamiento, donde se muestran las iteraciones y los valores de
  <code>Train Loss</code> y <code>Val Loss</code>, lo que permite ver cómo el modelo va aprendiendo a medida que
  avanza el entrenamiento.
</p>

<hr />
      </div>
    </article>

    <!-- Captura 3 -->
    <article class="capture">
      <div class="capture-header">
        <div class="capture-title">Captura 3 · Datos del entrenamiento</div>
        <div class="capture-tagline">GPU, vocabulario y tamaño del dataset.</div>
      </div>
      <div class="capture-image-wrapper">
        <div class="capture-image">
          <img src="image7.png" alt="Salida de consola con información de GPU, vocabulario y tokens" />
        </div>
      </div>
      <div class="capture-body">
        <div class="pill-row">
          <span class="pill">CUDA</span>
          <span class="pill">105 caracteres</span>
          <span class="pill">Tokens train/val</span>
        </div>
        <h3>Captura 3 – Evolución de las pérdidas</h3>
<p>
  En esta captura se muestra el bucle de entrenamiento del modelo, donde periódicamente se imprime el estado de la
  pérdida.
</p>
<p>
  Se indica el número de iteración y los valores de <code>Train Loss</code> y <code>Val Loss</code> cada 500
  iteraciones, comenzando en una pérdida de entrenamiento cercana a 4,89 y descendiendo progresivamente hasta valores
  en torno a 0,93.
</p>
<p>
  La pérdida de validación también disminuye desde aproximadamente 4,89 hasta alrededor de 1,35.
</p>
<p>
  Esta evolución refleja que el modelo está aprendiendo patrones del texto del Quijote y reduciendo el error tanto en
  los datos de entrenamiento como en los de validación a medida que avanzan las iteraciones.
</p>

<hr />
      </div>
    </article>

    <!-- Captura 4 -->
    <article class="capture">
      <div class="capture-header">
        <div class="capture-title">Captura 4 </div>
        <div class="capture-tagline">Train Loss y Val Loss durante las iteraciones.</div>
      </div>
      <div class="capture-image-wrapper">
        <div class="capture-image">
          <img src="image2.png" alt="Iteraciones de entrenamiento con valores de Train Loss y Val Loss" />
        </div>
      </div>
      <div class="capture-body">
        <div class="pill-row">
          <span class="pill">Iteraciones</span>
          <span class="pill">Monitorización</span>
          <span class="pill">Generalización</span>
        </div>
       <h3>Captura 4 – Hiperparámetros del modelo</h3>
<p>
  En esta captura se recogen los hiperparámetros definidos en el script <code>entrenar.py</code>.
</p>
<p>
  Entre ellos se encuentran <code>batch_size = 64</code> (tamaño de lote), <code>block_size = 256</code>
  (longitud del contexto de entrada), <code>max_iters = 10000</code> (número máximo de iteraciones)
  y <code>eval_interval = 500</code> (frecuencia de evaluación).
</p>
<p>
  También se especifica <code>learning_rate = 3e-4</code> y el dispositivo de cómputo
  <code>device = 'cuda' if torch.cuda.is_available() else 'cpu'</code>.
</p>
<p>
  Además, se detallan los parámetros de la arquitectura Transformer: <code>n_embd = 384</code>
  (dimensión de los embeddings), <code>n_head = 6</code> (número de cabezas de atención),
  <code>n_layer = 6</code> (número de capas) y <code>dropout = 0.2</code>.
</p>
<p>
  En los comentarios se explica que estos valores se han ajustado para aprovechar los 12 GB de VRAM de la RTX 4070 Ti,
  permitir un contexto más largo y aumentar la capacidad del modelo respecto a una configuración básica.
</p>

<hr />
      </div>
    </article>

    <!-- Captura 5 -->
    <article class="capture">
      <div class="capture-header">
        <div class="capture-title">Captura 5 · Hiperparámetros</div>
        <div class="capture-tagline">Configuración optimizada para la RTX 4070 Ti.</div>
      </div>
      <div class="capture-image-wrapper">
        <div class="capture-image">
          <img src="image6.png" alt="Bloque de código con hiperparámetros del modelo" />
        </div>
      </div>
      <div class="capture-body">
        <div class="pill-row">
          <span class="pill">batch_size = 64</span>
          <span class="pill">block_size = 256</span>
          <span class="pill">n_head = 6</span>
          <span class="pill">dropout = 0.2</span>
        </div>
       <h3>Captura 5 – Texto generado y guardado del modelo</h3>
<p>
  En esta captura se ve el mensaje “Entrenamiento completado! Generando texto...” seguido de un bloque de texto
  generado por el modelo.
</p>
<p>
  El contenido utiliza vocabulario y estructuras propias del Quijote, aunque con frases parcialmente incoherentes
  debido al tamaño limitado del modelo y a que trabaja a nivel de caracteres.
</p>
<p>
  Este resultado demuestra que el modelo ha aprendido a imitar el estilo del corpus, combinando palabras arcaicas
  y giros lingüísticos característicos.
</p>
<p>
  Al final de la salida aparece el mensaje “Modelo guardado como <code>quijote_model.pth</code>”, indicando que los
  pesos entrenados se han almacenado en un archivo para poder reutilizar el modelo posteriormente sin necesidad de
  reentrenarlo desde cero.
</p>

<hr />
      </div>
    </article>

    <!-- Captura 6 -->
    <article class="capture">
      <div class="capture-header">
        <div class="capture-title">Captura 6 · Texto generado</div>
        <div class="capture-tagline">Salida de ejemplo tras completar el entrenamiento.</div>
      </div>
      <div class="capture-image-wrapper">
        <div class="capture-image">
          <img src="image5.png" alt="Bloque de texto generado por el modelo con estilo del Quijote" />
          <img src="image4.png" alt="Bloque de texto generado por el modelo con estilo del Quijote" />
        </div>
      </div>
      <div class="capture-body">
        <div class="pill-row">
          <span class="pill">Modelo de caracteres</span>
          <span class="pill">Estilo Quijote</span>
          <span class="pill">quijote_model.pth</span>
        </div>
       <h3>Captura 6 – Nueva ejecución y guardado del modelo</h3>
<p>
  En la última captura se muestra una nueva ejecución de <code>python entrenar.py</code> dentro del mismo entorno
  virtual.
</p>
<p>
  De nuevo se indica que se está utilizando la GPU <code>cuda</code> con la NVIDIA GeForce RTX 4070 Ti y la VRAM
  disponible.
</p>
<p>
  A continuación se muestra de forma directa el mensaje “Modelo guardado como <code>quijote_model.pth</code>”, sin
  detallar todo el proceso de entrenamiento.
</p>
<p>
  Esta captura refleja que el script puede ejecutarse varias veces para continuar el entrenamiento, ajustar parámetros
  o simplemente volver a guardar el modelo actualizado, manteniendo siempre el archivo
  <code>quijote_model.pth</code> como salida final del proceso.
</p>
      </div>
    </article>

   

<footer>
  <div class="footer-inner">
    <span>© 2026 · Pre entrenamiento · Proyecto NanoQuijote.</span>
    <span>Autor de la documentación: [tu nombre]</span>
  </div>
</footer>

</body>
</html>
